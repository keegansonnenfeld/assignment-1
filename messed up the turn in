#calculating momentem
def Momentum(m, v):
    return (float(m) * float(v))

#calc energy
def KineticEnergy(m, v):
    return (float(m) * float(v) * float(v))

#inputs
M = input("enter the Mass :")

V = input("enter the Velocity :")



print(" the momentum is " + str(Momentum(M, V)),"kg*m/s",)

print(" the kinetic energy is " + str(KineticEnergy(M, V)),"jules",)



calculaing triangles
#the triangle sides
a = float(input("Enter the first side: "))
b = float(input("Enter the second side: "))
c = float(input("Enter the third side: "))
print("")
#Compute the sides
if ((a**2 == b**2 + c**2) or (a**2 + b**2 == c**2) or (a**2 + c**2 == b**2)):
    print("The triangle is a right triangle.")
else:
    print("The triangle is not a right triangle.")
    # _Check for equilateral triangle
    if ( a == b == c):
        print("The triangle is equilateral triangle")



word counter
try:
    f = open(input("Enter input filename:  "))
    d = {}
    for line in f:

        for word in line.split():
            if word not in d:
                d[word] = 0
            d[word] += 1
    f.close()
    num_words = 0
    for word, count in reversed(sorted(d.items(), key=lambda x: x[1])):
        print(word, count)
        num_words += 1
        if num_words == 30:
            break
except:
    print("File not found!")



pi tolorance 
tolerance = float(input("Enter the tolerance: "))
pi = 0
i = 0
while 4 / (2 * i + 1) >= tolerance:
    pi += ((-1) ** i) * 4 / (2 * i + 1)
    i += 1
print("The approximation of pi is:", pi)

problem 5
from __future__ import division
import nltk, re, pprint
from urllib import request
from bs4 import BeautifulSoup
from nltk.probability import FreqDist
#
# Assign URL of the web page to be processed
#
url = "https://edition.cnn.com/2020/10/06/politics/donald-trump-coronavirus-white-house-biden/index.html"
#
# Read the HTML from the URL
#
html = request.urlopen(url).read()
#
# Get text (clean html) using BeautifulSoup get_text method
#
raw = BeautifulSoup(html).get_text()
#
# Tokenize or get words
#
tokens = nltk.word_tokenize(raw)
#
# HTML Words
#
htmlwords = ['https', 'http', 'display', 'button', 'hover',
             'color', 'background', 'height', 'none', 'target',
             'WebPage', 'reload', 'fieldset', 'padding', 'input',
            'select', 'textarea', 'html', 'form', 'cursor',
            'overflow', 'format', 'italic', 'normal', 'truetype',
            'before', 'name', 'label', 'float', 'title', 'arial', 'type',
            'block', 'audio', 'inline', 'canvas', 'margin', 'serif', 'menu',
            'woff', 'content', 'fixed', 'media', 'position', 'relative', 'hidden',
            'width', 'clear', 'body', 'standard', 'expandable', 'helvetica',
            'fullwidth', 'embed', 'expandfull', 'fullstandardwidth', 'left', 'middle',
            'iframe', 'rgba', 'selected', 'scroll', 'opacity',
            'center', 'false', 'right']
#
# Get words meeting criteria such as words having only alphabets,
# words of length > 4 and words not in htmlwords
#
words = [w for w in tokens if w.isalpha() and len(w) > 4 and w.lower() not in htmlwords]
#
# Create NLTK Text instance to use NLTK APIs
#
text = nltk.Text(words)
#
# Create Frequency distribution to see frequency of words
#
freqdist = FreqDist(text)
freqdist.plot(30)
